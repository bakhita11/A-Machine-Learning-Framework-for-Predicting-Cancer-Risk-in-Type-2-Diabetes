{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME6cENy3rZE62NLu2C+9+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bakhita11/A-Machine-Learning-Framework-for-Predicting-Cancer-Risk-in-Type-2-Diabetes/blob/main/AI_Prediction_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set parameters\n",
        "n_days = 30\n",
        "intervals_per_day = 96  # 15-minute intervals in 24 hours\n",
        "total_rows = n_days * intervals_per_day\n",
        "\n",
        "# Generate timestamps\n",
        "start_time = datetime(2025, 1, 1, 0, 0)\n",
        "timestamps = [start_time + timedelta(minutes=15 * i) for i in range(total_rows)]\n",
        "\n",
        "# Simulate BG data\n",
        "np.random.seed(42)\n",
        "bg_rl = np.random.normal(110, 15, size=total_rows)        # RL agent\n",
        "bg_baseline = np.random.normal(140, 20, size=total_rows)  # Baseline\n",
        "\n",
        "# Clamp values to plausible physiological range\n",
        "bg_rl = np.clip(bg_rl, 40, 400)\n",
        "bg_baseline = np.clip(bg_baseline, 40, 400)\n",
        "\n",
        "# Feature engineering: rolling mean, difference, time of day\n",
        "bg_rl_rolling = pd.Series(bg_rl).rolling(window=4, min_periods=1).mean()  # 1-hour rolling mean\n",
        "bg_diff = bg_rl - bg_baseline\n",
        "time_of_day = [(ts.hour + ts.minute/60) for ts in timestamps]\n",
        "\n",
        "# Synthetic binary target: 1 if RL agent BG > 180 (hyperglycemia event), else 0\n",
        "event = (bg_rl > 180).astype(int)\n",
        "\n",
        "# Build DataFrame for ML\n",
        "data_encoded = pd.DataFrame({\n",
        "    'BG_RL_Agent': bg_rl,\n",
        "    'BG_Baseline': bg_baseline,\n",
        "    'BG_RL_1hRollingMean': bg_rl_rolling,\n",
        "    'BG_Difference': bg_diff,\n",
        "    'TimeOfDay': time_of_day,\n",
        "    'event': event  # This is your binary target variable\n",
        "})\n",
        "\n",
        "# Optional: Save to CSV\n",
        "data_encoded.to_csv('simulated_ml_data.csv', index=False)\n",
        "print(\"ML-ready DataFrame 'data_encoded' created and saved as 'simulated_ml_data.csv'.\")\n",
        "print(data_encoded.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra75mo9N6vL3",
        "outputId": "daf19764-ec65-472c-a423-314d8c1a1d14"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ML-ready DataFrame 'data_encoded' created and saved as 'simulated_ml_data.csv'.\n",
            "   BG_RL_Agent  BG_Baseline  BG_RL_1hRollingMean  BG_Difference  TimeOfDay  \\\n",
            "0   117.450712    95.235375           117.450712      22.215337       0.00   \n",
            "1   107.926035    97.585997           112.688374      10.340039       0.25   \n",
            "2   119.715328   127.862696           115.030692      -8.147368       0.50   \n",
            "3   132.845448   149.153732           119.484381     -16.308284       0.75   \n",
            "4   106.487699    85.049903           116.743628      21.437796       1.00   \n",
            "\n",
            "   event  \n",
            "0      0  \n",
            "1      0  \n",
            "2      0  \n",
            "3      0  \n",
            "4      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHUDg9p01dHT",
        "outputId": "1034a66d-ae7b-4bfc-8214-4ec5e68885bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total patients: 500\n",
            "Total rows: 1440000\n",
            "Target class distribution:\n",
            " event\n",
            "1    720054\n",
            "0    719946\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Parameters\n",
        "n_patients = 500\n",
        "n_days = 30\n",
        "intervals_per_day = 96  # 15-min intervals\n",
        "total_rows_per_patient = n_days * intervals_per_day\n",
        "\n",
        "start_time = datetime(2025, 1, 1, 0, 0)\n",
        "\n",
        "all_patients = []\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "for pid in range(n_patients):\n",
        "    timestamps = [start_time + timedelta(minutes=15 * i) for i in range(total_rows_per_patient)]\n",
        "    bg_rl = np.random.normal(110, 15, size=total_rows_per_patient)\n",
        "    bg_baseline = np.random.normal(140, 20, size=total_rows_per_patient)\n",
        "    bg_rl = np.clip(bg_rl, 40, 400)\n",
        "    bg_baseline = np.clip(bg_baseline, 40, 400)\n",
        "    bg_rl_rolling = pd.Series(bg_rl).rolling(window=4, min_periods=1).mean().values\n",
        "    bg_diff = bg_rl - bg_baseline\n",
        "    time_of_day = [(ts.hour + ts.minute/60) for ts in timestamps]\n",
        "    is_night = [1 if 0 <= ts.hour < 6 else 0 for ts in timestamps]\n",
        "    interaction = bg_rl * bg_baseline\n",
        "    bg_rl_lag1 = np.roll(bg_rl, 1)\n",
        "    bg_rl_lag1[0] = bg_rl[0]\n",
        "\n",
        "    noise = np.random.normal(0, 1, size=total_rows_per_patient)\n",
        "    linear_score = (\n",
        "        0.025 * bg_rl +\n",
        "        -0.012 * bg_baseline +\n",
        "        0.018 * bg_diff +\n",
        "        0.009 * np.array(time_of_day) +\n",
        "        0.02 * interaction +\n",
        "        0.015 * bg_rl_lag1 +\n",
        "        0.05 * np.array(is_night) +\n",
        "        noise\n",
        "    )\n",
        "    threshold = np.percentile(linear_score, 50)\n",
        "    event = (linear_score > threshold).astype(int)\n",
        "    flip_idx = np.random.choice(total_rows_per_patient, size=int(0.05 * total_rows_per_patient), replace=False)\n",
        "    event[flip_idx] = 1 - event[flip_idx]\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'PatientID': pid,\n",
        "        'Timestamp': timestamps,\n",
        "        'BG_RL_Agent': bg_rl,\n",
        "        'BG_Baseline': bg_baseline,\n",
        "        'BG_RL_1hRollingMean': bg_rl_rolling,\n",
        "        'BG_Difference': bg_diff,\n",
        "        'TimeOfDay': time_of_day,\n",
        "        'IsNight': is_night,\n",
        "        'Interaction': interaction,\n",
        "        'BG_RL_Lag1': bg_rl_lag1,\n",
        "        'event': event\n",
        "    })\n",
        "    all_patients.append(df)\n",
        "\n",
        "data_encoded = pd.concat(all_patients, ignore_index=True)\n",
        "\n",
        "print(\"Total patients:\", data_encoded['PatientID'].nunique())\n",
        "print(\"Total rows:\", len(data_encoded))\n",
        "print(\"Target class distribution:\\n\", data_encoded['event'].value_counts())\n",
        "\n",
        "# Split by patient\n",
        "patient_ids = data_encoded['PatientID'].unique()\n",
        "train_pids, test_pids = train_test_split(patient_ids, test_size=0.2, random_state=42, stratify=None)\n",
        "train_data = data_encoded[data_encoded['PatientID'].isin(train_pids)]\n",
        "test_data = data_encoded[data_encoded['PatientID'].isin(test_pids)]\n",
        "\n",
        "X_train = train_data.drop(columns=['event', 'PatientID', 'Timestamp'])\n",
        "y_train = train_data['event']\n",
        "X_test = test_data.drop(columns=['event', 'PatientID', 'Timestamp'])\n",
        "y_test = test_data['event']\n",
        "\n",
        "# Feature Selection with RFECV (fit on training data only)\n",
        "rf_for_fs = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rfecv = RFECV(estimator=rf_for_fs, step=1, cv=5, scoring='roc_auc', n_jobs=-1)\n",
        "rfecv.fit(X_train, y_train)\n",
        "selected_features = X_train.columns[rfecv.support_]\n",
        "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
        "print(\"Selected features:\", list(selected_features))\n",
        "\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "# Hyperparameter Tuning\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 300),\n",
        "    'max_depth': randint(3, 20),\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rand_search = RandomizedSearchCV(\n",
        "    rf, param_distributions=param_dist, n_iter=30, cv=5,\n",
        "    scoring='roc_auc', n_jobs=-1, random_state=42\n",
        ")\n",
        "rand_search.fit(X_train_selected, y_train)\n",
        "best_rf = rand_search.best_estimator_\n",
        "print(\"Best hyperparameters:\", rand_search.best_params_)\n",
        "\n",
        "# Model Training and Evaluation\n",
        "best_rf.fit(X_train_selected, y_train)\n",
        "y_pred = best_rf.predict(X_test_selected)\n",
        "y_proba = best_rf.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_proba)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"AUC: {auc:.3f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "# Feature Importance Visualization\n",
        "importances = best_rf.feature_importances_\n",
        "sorted_idx = np.argsort(importances)[::-1]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(selected_features[sorted_idx], importances[sorted_idx])\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"Top Features from Random Forest Model\")\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Cross-Validation AUC on training set\n",
        "cv_auc = cross_val_score(best_rf, X_train_selected, y_train, cv=5, scoring='roc_auc')\n",
        "print(f\"5-Fold Cross-Validated AUC (train set): {cv_auc.mean():.3f} ± {cv_auc.std():.3f}\")\n",
        "\n",
        "# Optional: Compute summary statistics for reporting\n",
        "print(\"BG_RL_Agent mean ± std:\", data_encoded['BG_RL_Agent'].mean(), \"±\", data_encoded['BG_RL_Agent'].std())\n",
        "print(\"BG_Baseline mean ± std:\", data_encoded['BG_Baseline'].mean(), \"±\", data_encoded['BG_Baseline'].std())\n",
        "print(\"% Time <70 mg/dL (RL):\", (data_encoded['BG_RL_Agent'] < 70).mean() * 100)\n",
        "print(\"% Time <70 mg/dL (Baseline):\", (data_encoded['BG_Baseline'] < 70).mean() * 100)\n",
        "print(\"Coefficient of Variation (RL):\", data_encoded['BG_RL_Agent'].std() / data_encoded['BG_RL_Agent'].mean() * 100)\n",
        "print(\"Coefficient of Variation (Baseline):\", data_encoded['BG_Baseline'].std() / data_encoded['BG_Baseline'].mean() * 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "X8aiWGHuo3oG"
      }
    }
  ]
}